\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[frenchb]{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{amsmath, amsthm, amssymb}
\usepackage[lined,boxed]{algorithm2e}

\sloppy

\title{Le problème du voyageur de commerce : Implémentation d'un algorithme de résolution}
\author{Guéneau Armaël \and Gledel Valentin}
\date{\today}

\begin{document}
\maketitle

\tableofcontents

\newpage

\addcontentsline{toc}{section}{Introduction}
\section*{Introduction}

\paragraph*{}
Le «~Voyageur du commerce~» est un problème algorithmique classique, pour lequel de nombreuses solutions approchées existent, bien que la résolution exacte soit difficile. Celui-ci peut se modéliser par un voyageur de commerce possédant une liste de villes à visiter pour vendre ses produits, et qui cherche à minimiser le temps qu’il passe sur la route. Connaissant la liste des villes et les distances entres elles, on veut alors trouver l’ordre dans lequel les parcourir pour que la distance totale parcourue soit minimale. Ce problème est NP-complet, il nous est donc impossible de trouver un algorithme trouvant une solution optimale et fonctionnant en un temps raisonnable.
\paragraph*{}
Dans le cadre du projet~1 en C, nous avons alors implémenté en binôme un algorithme de résolution approchée de ce problème, ainsi qu’une interface utilisateur permettant de sélectionner aisément les villes à parcourir par le voyageur dans une base de donnée.
L’algorithme choisi repose sur le parcours d'un arbre couvrant minimal pour le graphe des villes, construit à l'aide de l'algorithme de Kruskal. Il nous a fallu ensuite implémenter une base de données stockant des villes à parcourir par le voyageur et une interface utilisateur.
\paragraph*{}
Nous allons tout d’abord présenter les algorithmes que nous avons cherché à implémenter tout au long du projet : ceux-ci reposant sur des structures sous-jacentes, celà fera apparaître les contraintes sur celles-ci, ce qui sera attendu a priori. Alors, nous pourrons détailler leur implémentation, sous forme de bibliothèques indépendantes, prêtes à être utilisées ultérieurement. Ceci étant fait, et des bibliothèques propres à notre disposition, nous pourrons expliciter notre implémentation des algorithmes utilisant ces structures. Finalement, nous parlerons des problématiques liées au développement en langage de programmation C, les bibliothèques et les outils utilisés.

\bigskip

\section{Algorithmes}

\subsection{TSP}
Le cœur du projet repose sur l'utilisation d'un algorithme glouton, nommé ici \emph{TSP}. Celui-ci donne une solution approchée au problème du voyageur du commerce, appelée \textit{tournée} , sous la forme d'une liste de villes. La description de l'algorithme est la suivante :

\begin{algorithm}[H]
  \SetAlgoLined
  \KwData{Le graphe $G$ des villes et sa fonction de poids $w$}
  \KwResult{\textit{Tournée} pour le voyageur du commerce (liste de villes)}
  $T := $ un arbre couvrant minimal de $G$\;
  $L := $ parcours\_préfixe($T$)\;
  retourner $L$\;
  \caption{Algorithme TSP}
\end{algorithm}

\emph{TSP} repose ainsi sur des structures de graphe, d'arbre et de liste. \\
\begin{itemize}
\item Le graphe est donné par sa fonction de poids, et ici \emph{TSP} n'impose pas de contrainte supplémentaire sur les opérations que l'on veut pouvoir faire sur le graphe, puisqu'il le passe simplement en argument à la fonction de calcul d'arbre couvrant minimal.
\item La structure d'arbre doit pouvoir se parcourir efficacement. Une implémentation telle que réalisée en TP semble convenir pour le moment (un arbre est un nœud racine et des pointeurs vers les fils), adaptée pour gérer un nombre quelconque de fils.
\end{itemize}

\subsection{Algorithme de Kruskal}
\label{sse:kruskalAlgo}

\paragraph*{} L'algorithme de \emph{Kruskal} permet de construire un arbre couvrant minimal pour un graphe donné, à savoir un arbre composé de tous les sommets du graphe, et de poids minimal. Il commence par trier toutes les arêtes par ordre croissant de poids, puis construit une forêt qui est initialement composée d'arbres à un nœud, correspondant aux sommets du graphe. \\
Il s'agit ensuite de lier les arbres en parcourant les arêtes (triées) : si les deux sommets que lie l'arête appartiennent à des arbres différents dans la forêt, on relie ces deux arbres par ces sommets; sinon on passe à l'arête suivante.
\paragraph*{}
Formellement cela s'écrit :

\medskip

\begin{algorithm}[H]
\SetAlgoLined
\KwData{Le graphe $G=(V, E)$ des villes et sa fonction de poids $w$}
\KwResult{$T$, un arbre couvrant minimal du graphe}
Trier $E$ par ordre croissant de poids selon $w$\;
Construire la forêt $F$, composée des arbres associés aux sommets\;
\ForEach{$e=(v1, v2)$ $\in$ $E$ $trié$}{
  \eIf{$v1$ et $v2$ appartiennent à un arbre différent}{
    Lier $v1$ et $v2$, et donc les arbres qui les contiennent\;
  }{
    Passer à l'arête suivante\;
  }
}
\caption{Algorithme de \emph{Kruskal}}
\end{algorithm}

\medskip

Pour améliorer les performances, nous voulons pouvoir vérifier que deux sommets n'appartiennent pas au même arbre et lier deux arbres en temps constant. Cela entraîne deux contraintes :
\begin{itemize}
\item Les arbres doivent en fait être non-enracinés pour pouvoir les fusionner aisément.
\item La forêt doit permettre la vérification instantanée de l'appartenance à un arbre.
\end{itemize}

\subsection{Base de données}

\paragraph*{}
En parallèle de l'algorithme principal, il était nécessaire d'implémenter une base de données performante, utilisée pour stocker des villes et leurs coordonnées. Les opérations recherchées sont les opérations classiques : ajouter une correspondance (\texttt{nom} $\rightarrow$ \texttt{(x, y)}) à la table, et trouver les coordonnées \texttt{(x, y)} connaissant le nom.

\paragraph*{}
Nous aurions pu implémenter une table de hachage générique, cependant ici, connaître la nature des clés (il s'agit de chaînes de caractères) nous permettra, lors du choix de la structure, d'optimiser grandement.

\section{Les structures de données}

Une fois les algorithmes choisis et qu'a été définie la manière précise dont ils ont besoin d'utiliser les structures sous-jacentes, il faut effectivement les choisir et les implémenter. La plupart des structures ont été conçues sous forme de bibliothèques de sorte à pouvoir éventuellement resservir pour d'autres projets. Cependant, pour l'algorithme de \emph{Kruskal} nous avons développé des structures plus spécifiques.

\subsection{Le type \texttt{Generic}}

Lorsque l'on cherche à implémenter des bibliothèques génériques en C, un problème qui se pose est celui de la généricité. Comment implémenter une structure pouvant contenir n'importe quel type de données ? Il ne semble pas avoir solution magique en C, mais nous pensons avoir trouvé une solution assez satisfaisante.

Après lecture du code de nombreuses bibliothèques contenant des structures de données «~génériques~» implémentées en C, il apparaît que ce qui est couramment fait est de stocker dans la structure un type \texttt{void*}. En effet, celui-ci permet de représenter tout type de pointeur, puisque l'on peut «~caster~» de manière transparente tout pointeur en \texttt{void*} et inversement (c'est ce qu'utilise la fonction \texttt{malloc()} par exemple, qui retourne un \texttt{void*}).

Cependant, lorsque l'on veut stocker un type non pointé, c'est quasiment impossible : soit l'on alloue de la mémoire pour le stocker (ce qui est très pénible : être obligé d'allouer de la mémoire pour un \texttt{int}, et garder un pointeur dessus, qui est de la même taille (ou plus) que la donnée pointée), soit l'on «~caste~» directement le \texttt{int} en \texttt{void*}. Ceci est en fait totalement non-sécure, rien ne garantissant que les types aient la même taille en mémoire (et en effet, ce n'est par exemple pas le cas en amd64).

Nous avons alors abouti à la solution suivante : on utilise un type, nommé \texttt{Generic}\footnote{lib/generic.h}, et qu'utiliseront nos structures de données. Celui-ci est en fait une \texttt{union} des types scalaires usuels, et d'un \texttt{void*} pour représenter les pointeurs.

Pour «~convertir~» une variable donnée \texttt{v} (supposons là de type \texttt{int} ici) en \texttt{Generic}, il suffit de faire \texttt{g = (Generic)v}. À l'inverse, un \texttt{Generic} étant donné, accéder à la variable \texttt{v} de type \texttt{int} s'écrit \texttt{g.i}\footnote{On note qu'il n'y a pas de sécurité de types : il faut savoir à l'avance ce qui a été stocké dans un \texttt{Generic} car l'information de typage a été perdue.}. 

\subsection{Les \texttt{Vector}s}
Après avoir détaillé les algorithmes, il nous est apparu que nous allions avoir besoin bien entendu de tableaux statiques, mais aussi qu'il serait commode, pour plus de souplesse, de pouvoir faire grandir ces tableaux dynamiquement, à la demande.

Nous avons donc implémenté ce que nous appelons les \texttt{Vector}s\footnote{lib/vector.h} : il s'agit de tableaux standard, avec en plus la possibilité d'adresser des éléments à un indice arbitrairement élevé, le tableau grandissant à la demande. La politique d'expansion est de doubler la taille du tableau dès que plus de mémoire est nécessaire : ceci permet d'avoir un coût d'insertion d'un nouvel élément en $O(1)$ amorti (voir \cite{cormen} p. 463, 17-4).

Ils se sont révélés très utiles, sont utilisées à de multiples endroits du projet et apportent une grande flexibilité pour de bonnes performances.

\subsection{Le graphe}

La description même de l'algorithme reposant sur la notion de graphe, nous avions commencé par implémenter une bibliothèque de manipulation de graphes, tout d'abord sous la forme de listes d'arètes (contenant les poids). Voyant que la taille du graphe en mémoire explosait pour un nombre un peu grand de villes (typiquement quelques milliers), nous avons changé notre implémentation pour une représentation avec matrice de poids. Celle-ci économise en effet toute la mémoire prise par les pointeurs de chaînage. Le gain en mémoire fut substantiel, divisant par plus de 2 la consommation mémoire. Celle-ci restait cependant importante, avec une croissance quadratique (en $\frac{n(n-1)}{2}$ précisément).

Finalement, tirant parti du fait que le graphe est complet, et qu'en général, on ne calcule les poids qu'un nombre réduit de fois, nous avons totalement supprimé la matrice de poids précalculée. On utilise au final un ensemble de tableaux (structure \texttt{Towns}\footnote{lib/towns.h} stockant les noms des villes, et leurs coordonnées. Les poids sont alors calculés à la demande.

Pour accélérer légèrement les calculs, on utilise en fait la distance au carré comme poids. Ainsi, on s'économise un calcul de racine sur des flottants, potentiellement coûteux (et ça ne change pas le résultat, la fonction carré étant croissante).

\subsection{Arbres non-enracinés}

Nos arbres doivent permettre un parcours (préfixe) aisé, et surtout la fusion de deux arbres en temps constant.

Les arbres non-enracinés ("free trees" en anglais, d'où le nom \texttt{Ftree}\footnote{lib/ftree.h}) permettent de lier deux arbres par deux de leur noeuds sans avoir à se préoccuper de notion de racine à déplacer. Ceci est réalisé en stockant dans chaque nœud de l'arbre un tableau (\texttt{Vector}) de ses voisins. Ainsi chaque noeud de l'arbre peut représenter l'ensemble de l'arbre, alors qu'avec une implémentation standard, il est impossible de remonter vers un parent éventuel.

\begin{verbatim}
typedef struct {
  Generic data;
  Vector *neighbors;
  int neighborsNb;
} Ftree;
\end{verbatim}

\subsection{Structures utilisées dans l'algorithme de \emph{Kruskal}}

Les structures liées à l'algorithmes de \emph{Kruskal} sont particulières car nous ne les avons pas développées de manière à être réutilisables. La liste d'arêtes, comme les autres types listes que l'on retrouve dans le projet, n'est en rien générale, et les fonctions sur la structure des forêts sont spécifiques à l'algorithme de \emph{Kruskal}.

Ceci découle du fait qu'en C, la généricité a pour prix une certaine lourdeur. Pour un type comme la liste pour lequel on ne voudra faire qu'une opération très simple (ajouter un élément en tête), il nous a semblé plus simple de créer des types listes spécifiques là où nous en avions besoin avec la fonction \texttt{cons} correspondante.

\subsubsection{Forêts}

Les forêts correspondent au type \texttt{Forest} du fichier \texttt{kruskal.h}.

La contrainte sur cette structure est que, deux nœuds de \texttt{Ftree} étant donnés, on veut pouvoir vérifier en temps constant si ces nœuds sont en fait dans le même \texttt{Ftree}.

La forêt est ici codée par un \texttt{Vector}, étiquetée par les indices des nœuds. Sachant qu'initialement, chaque case du tableau correspond à un \texttt{Ftree} d'un nœud, chaque case du tableau correspond au final à un nœud de \texttt{Ftree}.

On va ensuite effectuer des opérations de fusion de différents \texttt{Ftree}s. Chaque case du tableau pointera alors vers un nœud d'un \texttt{Ftree} - son représentant. L'idée est que, chaque case correspondant à un nœud de \texttt{Ftree}, si l'on a un \texttt{Ftree} donné, pour chaque nœud du \texttt{Ftree}, on indiquera dans la case correspondante le \textit{même} représentant du \texttt{Ftree}.\\
Tester l'appartenance à un \texttt{Ftree} revient alors à regarder si les représentants sont les mêmes.

Ceci a cependant un coût : après une fusion, il est nécessaire de mettre à jour le représentant d'un des deux arbres fusionnés, pour correspondre avec celui de l'autre, ce qui a un coût linéaire.

On a bien rempli l'objectif : la vérification est en $O(1)$, mais le coût de maintien de l'exactitude de la structure est en $O(n)$ dans le pire cas.

\subsubsection{Listes d'arêtes}

L'algorithme de \emph{Kruskal} nécessite de trier les arêtes, il nous fallait donc une structure pour contenir ces arêtes. Nous avons choisi d'utiliser une liste, et d'utiliser par la suite l'algorithme de tri-fusion.

\begin{verbatim}
typedef struct {
  int n1;
  Ftree* addr1;
  int n2;
  Ftree* addr2;

  float weight;

  struct kedge *next;
} Kedge;
\end{verbatim}

Chaque arête contient son poids, les numéros des sommets qu'elle lie et des pointeur vers les nœuds de \texttt{Ftree} qui leur sont associés. Cela permet de lier les arbres en temps constant car on accède directement au bon noeud.

\subsection{Les tries comme bases de données}

Une trie est un arbre dont chaque arête est étiquetée par un caractère. Cette structure permet de rechercher un mot en temps linéaire en la taille de ce mot, car chaque chemin dans cet arbre représente un mot ou un préfixe. Ainsi pour rechercher un mot il suffit de chercher chacune des lettres qui le compose à chaque nœud de la trie.

Cette structure est également assez économique en mémoire, puisqu'il n'y a pas de redondance entre mots qui ont des préfixes communs.

\begin{verbatim}
struct trie {
  float coord_x;
  float coord_y;
  int is_word;
  Letter* letters;
};

struct letter {
  char letter;
  Trie* next;
  struct letter *tail;
};
\end{verbatim}

Il y a un choix à faire lors de l'implémentation d'une trie : à chaque nœud, on peut stocker les transitions partant de celui-ci sous forme d'une liste chaînée de lettres étiquetant les transitions, ou en stockant directement un tableau de taille 256, ce qui permet de s'affranchir du temps de parcours de la liste.

Nous avions au départ implémenté la deuxième solution, pour nous rendre compte qu'elle était très coûteuse en mémoire. En effet, les noms de villes sont majoritairement composés de caractères alphabétiques minuscules, ce qui n'utilise qu'une portion du tableau de 256 cases alloué.

Finalement, notre structure de trie\footnote{lib/trie.h} est construite à l'aide d'une sous structure, \texttt{Letter}, qui représente la liste transitions présentes à un nœud de la trie et la trie fille qui découle de chacune. \texttt{is\_word} permet de savoir à chaque étape de la trie si on se trouve à la fin d'un mot et \texttt{coord\_x}, \texttt{coord\_y} représentent les coordonnées de la ville dont c'est le nom.

\section{Implémentation des algorithmes}

\subsection{TSP}
L'algorithme \emph{TSP} ne fait en lui même pas grand chose : il s'agit d'appeler \emph{Kruskal}, puis de faire un parcours préfixe du \texttt{Ftree*} obtenu.

\paragraph*{}
Cela est fait de manière récursive par la fonction \texttt{prefixTravel\_}. Le parcours d'un \texttt{Ftree*} est presque naturel, il faut simplement prendre garde de passer en argument, lors de l'appel récursif, l'adresse du nœud duquel on vient, celui-ci étant également voisin du nouveau nœud sur lequel on appelle.

\subsection{Algorithme de Kruskal}

\paragraph*{}
Dans un premier temps il s'agit de construire la forêt. Connaissant le nombre de noeuds à l'avance, il suffit de créer un tableau d'arbres non-enracinés indexé par la case du tableau dans laquelle ils sont. On raisonne ici uniquement sur les indices des nœuds, les \texttt{Vector} de la structure \texttt{Towns} font la correspondance avec les noms et les coordonnées. Le nombre de nœuds est donc la seule donnée nécessaire.
\paragraph*{}
On crée ensuite la liste des arêtes en calculant au fur et à mesure les poids à partir des coordonnées et en ajoutant une arête pour chaque couple de ville, liste qu'on trie ensuite grâce à un tri fusion.
\paragraph*{}
Une fois la liste des arêtes triées et la forêt créés, il suffit d'appliquer l'algorithme de Kruskal comme expliqué dans la sous-section~\ref{sse:kruskalAlgo}, et en effectuant les manipulations post-fusion de \texttt{Ftree}s sur la forêt.

\subsection{Parcours de tries}

\medskip

\begin{algorithm}[H]
  \SetAlgoLined
  \KwData{La chaine de carractère $(c_i)_{i \in [0,n-1]}$ correspondant au nom de la ville recherchée et la trie contenant les données}
  \KwResult{Les coordonnées de cette ville ou une erreur si elle n'est pas présente}
  \eIf{La lettre $c_0$ est présente à cette étage de la trie} {
    \eIf{La chaine de caractère ne contient qu'un seul caractère} {
      \eIf{La trie est terminale à cet endroit} {
        Renvoyer les coordonnées\;
      }{
        Renvoyer une erreur\;
      }
    }{
      Appliquer cet algorithme à la trie fille et à la chaine $(c_i)_{i \in [1,n-1]}$ \;
    }
  }{
    Renvoyer une erreur\;
  }
\caption{Algorithme de parcours de trie}
\end{algorithm}

\medskip

La recherche du caractère à un étage donné de la trie se fait en temps constant donc la complexité est en $\Theta$(longueur de la chaine de caractères).

\section{Problématiques pratiques de développement : bibliothèques et outils utilisés}

\subsection{Bibliothèque de tests unitaires}
Une bonne pratique de développement est l'utilisation récurrente de tests unitaires : une fois des fonctions écrites, il s'agit d'écrire une suite de tests sur cette fonction, testant son comportement sur des valeurs d'entrée données, et vérifiant automatiquement la conformité de la sortie. Cela permet tout d'abord de détecter des bogues, l'oubli de cas particuliers, mais aussi, lors de factorisation ou modification de code existant, de vérifier que le nouveau code est toujours conforme.

L'objectif est de pouvoir créer des tests simplement, et de les lancer ensuite de manière automatique. Les bibliothèques existantes sur lesquelles nous nous sommes penchés nous ont semblées à la fois lourdes et compliquées à utiliser. Nous avons donc développé notre propre bibliothèque de tests unitaires, visant à être pleinement utilisable, tout en étant suffisamment minimale pour ne pas avoir à «~débugger les tests~».

Il s'agit d'un simple header, \texttt{minunit.h}\footnote{dans le dossier tests/}, qui, une fois inclus, permet :
\begin{itemize}
\item Créer une fonction de test avec \texttt{START\_TEST}, \texttt{END\_TEST}
\item Dans cette fonction, on fait des \texttt{assert()}, qui testent une valeur (typiquement une comparaison sur une valeur de retour), et renvoient un message d'erreur en cas d'échec.
\item Dans le corps principal de la fonction, on peut alors lancer les différents tests créés, et récupérer au final le nombre de tests réussis ou échoués, et afficher un résumé de l'ensemble des tests.
\end{itemize}

Et en bonus, des couleurs !

\subsection{Makefile avec gestion fine des dépendances}
Un Makefile, en plus de fournir les commandes pour construire automatiquement les binaires, doit pouvoir établir précisément, lors de la modification de quelques fichiers, les binaires objets (\texttt{.o}) à recompiler nécessairement. Pour de gros projets, il serait néfaste de mal gérer ceci, et de recompiler une grosse partie du code pour la modification d'un simple fichier. Si ce projet n'a pas forcément cette envergure, il nous a semblé important d'apprendre comment écrire un Makefile propre, gérant finement les dépendances au sein du projet entier. 

Pour cela, nous nous sommes appuyés sur l'article de Peter Miller (\cite{makefile}), décrivant une méthode propre de construction de Makefiles, à l'inverse des Makefiles récursifs, qu'il montre être totalement inefficients.

Celle-ci consiste en fait à faire générer à \texttt{gcc} la liste des dépendances d'un fichier, et de stocker ça dans un fichier particulier, lui-même étant en dépendance. Make, en chargeant tous ces fichiers, récupère toutes les informations de dépendances, et ne reconstruit que l'exact nécessaire.

\addcontentsline{toc}{section}{Conclusion}
\section*{Conclusion}
\paragraph*{}
Nous obtenons donc à l'aide de l'algorithme de Kruskal et de l'algorithme TSP, une résolution du problème du voyageur de commerce qui, même si elle n'est pas optimale, renvoie des résultats acceptable. En effet, les tests que nous avons effectuer nous ont permis de constater que les résultats obtenus ne contenaient pas de parcours absurdes dont il est évident qu'ils sont bien trop long.
\paragraph*{}
La structure de donnée crée à l'aide des tries permet de charger des milliers de villes (l'ensemble des villes française) en quelque seconde et de ressortir celle demandée presque instantanément.
\paragraph*{}
L'interface utilisateur utilisant les convention UNIX permet de chargés differentes bases de données (uniquement les grandes villes française ou aussi les petites communes), de rentrer une liste de ville à parcourir à la main ou à l'aide d'un fichier texte.
\paragraph*{}
Nous avons rencontrer des difficultées de compléxité qui empêchaient d'appliquer le programme à un trop grand nombre de ville (de l'ordre du millier) et qui nous ont amené à changer certaine de nos structure de données notament la structure de graphe pour obtenir des fonctions bien plus rapide.
\paragraph*{}
Toutefois, le programme n'est pas encore optimal. Même si appliquer l'algorithme à 3000 villes ne prend plus que 12 seconde, il reste difficile d'atteindre 10 000 villes. La structure de donnée stockant les arêtes peut être la source de cette faiblesse. Une amélioration possible serait de remplacer la structure de liste par un tableau qui permettrait de trier sur place les arêtes.


\begin{thebibliography}{00}

\bibitem{cormen}
  T. Cormen, C. Leiserson, R. Rivest, C. Stein,
  \textit{Introduction to Algorithms},
  MIT Press,
  3rd edition,
  2009.

\bibitem{makefile}
  P. Miller,
  \textit{Recursive Make Considered Harmful},
  AUUGN Journal of AUUG Inc.,
  1998.

\end{thebibliography}

\end{document}
